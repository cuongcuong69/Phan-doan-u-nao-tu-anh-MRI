# -*- coding: utf-8 -*-
"""
Chia train/val/test 70/15/15 cho dá»¯ liá»‡u 2D Ä‘Ã£ export:
D:\Project Advanced CV\data\processed\2d\labeled\Brain_001, Brain_002, ...

âœ… Stratify theo Ä‘áº·c tÃ­nh quan trá»ng (per-case) tÃ­nh tá»« mask 2D + Grade (HGG/LGG):
  - Grade (HGG/LGG) tá»« name_mapping.csv
  - has_ET (label==3)  [nhá»›: trÆ°á»›c Ä‘Ã³ map 4->3 khi export 2D]
  - size_bin theo quantile cá»§a tá»•ng pixel u (tumor_area_total)

âš ï¸ Fallback an toÃ n:
  - Náº¿u lá»›p stratify quÃ¡ nhá»: tá»± Ä‘á»™ng rÃºt gá»n (gradeÃ—hasETÃ—size â†’ gradeÃ—hasET â†’ hasET â†’ all)
  - Náº¿u khÃ´ng map Ä‘Æ°á»£c Grade, gÃ¡n 'Unknown' (vÃ  váº«n tÃ¡ch Ä‘Æ°á»£c nhá» fallback)

ðŸ“¦ Xuáº¥t:
  - CSV:  splits.csv  (1 dÃ²ng / ca, kÃ¨m Ä‘áº·c trÆ°ng & split)
  - JSON: splits.json (list id cho train/val/test)
  - TXT:  train.txt, val.txt, test.txt
"""

from pathlib import Path
import json
from typing import Dict, List, Tuple

import cv2
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split


# ============ Cáº¤U HÃŒNH (sá»­a táº¡i Ä‘Ã¢y náº¿u cáº§n) ============
ROOT                 = Path(r"D:\Project Advanced CV")
LABELED_REL          = Path(r"data\processed\2d\labeled")
OUT_REL              = Path(r"configs\splits_2d")

# ÄÆ°á»ng dáº«n raw 3D & mapping Grade
RAW_TRAIN_DIR        = ROOT / r"data\BraST2020\BraTS2020_TrainingData\MICCAI_BraTS2020_TrainingData"
NAME_MAPPING_CSV     = RAW_TRAIN_DIR / "name_mapping.csv"   # chá»©a cá»™t Grade

SEED           = 2025
TRAIN_RATIO    = 0.70
VAL_RATIO      = 0.15
TEST_RATIO     = 0.15
MIN_PER_STRAT  = 8      # tá»‘i thiá»ƒu / lá»›p khi stratify
# ========================================================


def find_mask_folder(brain_dir: Path) -> Path:
    """Há»— trá»£ cáº£ cáº¥u trÃºc 'mask' hoáº·c 'Label0'."""
    for cand in (brain_dir / "mask", brain_dir / "Label0"):
        if cand.exists() and cand.is_dir():
            return cand
    raise FileNotFoundError(f"KhÃ´ng tháº¥y thÆ° má»¥c mask/Label0 trong: {brain_dir}")


def imread_any(path: Path, flags=cv2.IMREAD_UNCHANGED):
    """Äá»c áº£nh unicode-safe trÃªn Windows."""
    data = np.fromfile(str(path), dtype=np.uint8)
    return cv2.imdecode(data, flags)


def load_mask_stats_for_case(brain_dir: Path) -> Dict:
    """
    TÃ­nh Ä‘áº·c trÆ°ng stratify tá»« toÃ n bá»™ mask PNG cá»§a 1 Brain_xxx.
    Giáº£ Ä‘á»‹nh mask sá»‘ hÃ³a: 0=BG, 1=NCR, 2=ED, 3=ET.
    """
    mdir = find_mask_folder(brain_dir)
    pngs = sorted(mdir.glob("*.png"))
    if not pngs:
        raise FileNotFoundError(f"KhÃ´ng cÃ³ mask PNG trong {mdir}")

    tumor_area_total = 0
    et_area_total = 0
    slices_with_tumor = 0

    for p in pngs:
        m = imread_any(p, cv2.IMREAD_UNCHANGED)
        if m is None:
            continue
        if m.ndim == 3:
            # Náº¿u lá»¡ trá» sang mask mÃ u (Label1), cá»‘ Ä‘á»c GRAY
            m = imread_any(p, cv2.IMREAD_GRAYSCALE)
            if m is None:
                continue

        m = m.astype(np.uint8)
        if (m > 0).any():
            slices_with_tumor += 1
            tumor_area_total += int((m > 0).sum())
            et_area_total    += int((m == 3).sum())

    return {
        "tumor_area_total": tumor_area_total,
        "et_area_total": et_area_total,
        "slices_with_tumor": slices_with_tumor,
        "has_tumor": int(tumor_area_total > 0),
        "has_et": int(et_area_total > 0),
    }


# ---------- Grade mapping ----------

def _read_brain_meta_case(brain_dir: Path) -> str:
    """
    Thá»­ Ä‘á»c tÃªn case gá»‘c tá»« meta trong Brain_xxx:
    - meta.json (key 'case_name')
    - _source_case.txt (1 dÃ²ng tÃªn case)
    KhÃ´ng cÃ³ thÃ¬ tráº£ ''.
    """
    meta_json = brain_dir / "meta.json"
    if meta_json.exists():
        try:
            jd = json.loads(meta_json.read_text(encoding="utf-8"))
            case_name = jd.get("case_name", "") or jd.get("case", "")
            if isinstance(case_name, str) and case_name.strip():
                return case_name.strip()
        except Exception:
            pass

    source_txt = brain_dir / "_source_case.txt"
    if source_txt.exists():
        try:
            line = source_txt.read_text(encoding="utf-8").strip()
            if line:
                return line
        except Exception:
            pass

    return ""


def _sorted_raw_cases() -> List[str]:
    """Danh sÃ¡ch case raw (Ä‘Ã£ sort) trong RAW_TRAIN_DIR, vÃ­ dá»¥ 'BraTS20_Training_001'."""
    if not RAW_TRAIN_DIR.exists():
        return []
    cases = [d.name for d in RAW_TRAIN_DIR.iterdir()
             if d.is_dir() and d.name.startswith("BraTS20_Training_")]
    return sorted(cases)


def _fallback_map_brain_to_case(brains: List[Path]) -> Dict[str, str]:
    """
    Fallback: Ã¡nh xáº¡ theo thá»© tá»± â€” Brain_001 â†” case thá»© 1 (sort theo tÃªn) â€¦,
    giáº£ Ä‘á»‹nh báº¡n Ä‘Ã£ export 2D theo Ä‘Ãºng thá»© tá»± case raw (script trÆ°á»›c Ä‘Ã³ lÃ m nhÆ° váº­y).
    """
    raw_cases_sorted = _sorted_raw_cases()
    mapping = {}
    if len(raw_cases_sorted) < len(brains):
        # váº«n map theo min(len))
        n = min(len(raw_cases_sorted), len(brains))
    else:
        n = len(brains)
    for i in range(n):
        mapping[brains[i].name] = raw_cases_sorted[i]
    return mapping


def load_grade_mapping() -> Dict[str, str]:
    """
    Äá»c name_mapping.csv vÃ  tráº£ dict: {case_name: Grade}
    Cá»‘ gáº¯ng dÃ² tÃªn cá»™t chá»©a case_name & Grade linh hoáº¡t.
    """
    if not NAME_MAPPING_CSV.exists():
        return {}

    df = pd.read_csv(NAME_MAPPING_CSV)
    # TÃ¬m cá»™t grade
    grade_col = None
    for c in df.columns:
        if c.strip().lower() == "grade":
            grade_col = c
            break
    if grade_col is None:
        # khÃ´ng cÃ³ grade
        return {}

    # TÃ¬m cá»™t case_name
    cand_cols = ["BraTS_2020_subject_ID", "BraTS20ID", "BraTS_ID", "Case", "case", "Name", "name", "Subject", "subject"]
    case_col = None
    for c in df.columns:
        if c in cand_cols:
            case_col = c
            break
    if case_col is None:
        # thá»­ suy diá»…n: chá»n cá»™t cÃ³ giÃ¡ trá»‹ giá»‘ng pattern 'BraTS20_Training_'
        for c in df.columns:
            vals = df[c].astype(str)
            if vals.str.startswith("BraTS20_Training_").any():
                case_col = c
                break
    if case_col is None:
        return {}

    mapping = {}
    for _, r in df.iterrows():
        name = str(r[case_col]).strip()
        grade = str(r[grade_col]).strip()
        if name:
            mapping[name] = grade
    return mapping


def attach_grade(df_cases: pd.DataFrame, brain_to_case: Dict[str, str], case_to_grade: Dict[str, str]) -> pd.DataFrame:
    df = df_cases.copy()
    grades = []
    raw_cases = []
    for brain in df["brain"]:
        case_name = _read_brain_meta_case(Path(ROOT / LABELED_REL / brain))
        if not case_name:
            case_name = brain_to_case.get(brain, "")
        raw_cases.append(case_name if case_name else "Unknown")

        g = case_to_grade.get(case_name, "Unknown") if case_name else "Unknown"
        grades.append(g if g in ("HGG", "LGG") else ("Unknown" if g else "Unknown"))

    df["raw_case"] = raw_cases
    df["grade"] = grades
    return df


# ---------- Stratify helpers ----------

def build_size_bins(areas: np.ndarray, min_per_bin: int = 10) -> Tuple[np.ndarray, List[str]]:
    """
    PhÃ¢n nhÃ³m kÃ­ch thÆ°á»›c theo quantile: thá»­ 3-bin â†’ náº¿u thiáº¿u máº«u, 2-bin â†’ náº¿u váº«n thiáº¿u, 1-bin.
    Tráº£ vá» chá»‰ sá»‘ bin (0..K-1) vÃ  tÃªn bin.
    """
    a = areas.astype(np.float64)
    if np.all(a == 0):
        return np.zeros_like(a, dtype=int), ["all_zero"]

    # 3-bin
    q1, q2 = np.quantile(a, [1/3, 2/3])
    bins3 = np.digitize(a, [q1, q2], right=False)  # 0,1,2
    if min((bins3 == i).sum() for i in (0, 1, 2)) >= min_per_bin:
        return bins3, ["small", "medium", "large"]

    # 2-bin
    q = np.quantile(a, 0.5)
    bins2 = np.digitize(a, [q], right=False)  # 0,1
    if min((bins2 == i).sum() for i in (0, 1)) >= min_per_bin:
        return bins2, ["small", "large"]

    # 1-bin
    return np.zeros_like(a, dtype=int), ["all"]


def make_stratify_labels(df: pd.DataFrame, min_per_stratum: int = 8) -> Tuple[pd.Series, List[str]]:
    """
    NhÃ£n stratify Æ°u tiÃªn Ä‘á»§ máº¡nh:
      1) grade Ã— has_et Ã— size_bin
      2) grade Ã— has_et
      3) has_et
      4) all
    """
    bins_idx, bin_names = build_size_bins(df["tumor_area_total"].values, min_per_bin=min_per_stratum)
    tmp = df.copy()
    tmp["size_bin_idx"] = bins_idx

    # Cáº¥p 1
    tmp["strat"] = (
        tmp["grade"].astype(str) + "_" +
        tmp["has_et"].astype(str) + "_" +
        tmp["size_bin_idx"].astype(str)
    )
    counts = tmp["strat"].value_counts()
    if counts.empty or counts.min() < min_per_stratum:
        # Cáº¥p 2
        tmp["strat"] = tmp["grade"].astype(str) + "_" + tmp["has_et"].astype(str)
        counts = tmp["strat"].value_counts()
        if counts.empty or counts.min() < min_per_stratum:
            # Cáº¥p 3
            tmp["strat"] = tmp["has_et"].astype(str)
            counts = tmp["strat"].value_counts()
            if counts.empty or counts.min() < min_per_stratum:
                # Cáº¥p 4
                tmp["strat"] = "all"

    return tmp["strat"], bin_names


def main():
    # Kiá»ƒm tra tá»‰ lá»‡
    assert abs((TRAIN_RATIO + VAL_RATIO + TEST_RATIO) - 1.0) < 1e-6, "Tá»•ng tá»‰ lá»‡ pháº£i = 1.0"

    labeled_dir = ROOT / LABELED_REL
    out_dir = ROOT / OUT_REL
    out_dir.mkdir(parents=True, exist_ok=True)

    # 1) Liá»‡t kÃª Brain_xxx
    brains = sorted(d for d in labeled_dir.iterdir() if d.is_dir() and d.name.lower().startswith("brain_"))
    if not brains:
        raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y Brain_xxx trong: {labeled_dir}")

    # 2) TÃ­nh Ä‘áº·c trÆ°ng stratify tá»« mask
    rows = []
    for b in brains:
        try:
            feats = load_mask_stats_for_case(b)
        except Exception as e:
            print(f"[WARN] Bá» qua {b.name}: {e}")
            continue
        rows.append({"brain": b.name, **feats})
    df = pd.DataFrame(rows)
    if df.empty:
        raise RuntimeError("KhÃ´ng thu Ä‘Æ°á»£c Ä‘áº·c trÆ°ng nÃ o Ä‘á»ƒ stratify.")

    # 3) GÃ¡n Grade
    case_to_grade = load_grade_mapping()
    brain_to_case = {}

    # Æ¯u tiÃªn: Ä‘á»c meta trong má»—i Brain_xxx
    for b in brains:
        case_name = _read_brain_meta_case(b)
        if case_name:
            brain_to_case[b.name] = case_name

    # Fallback theo thá»© tá»± náº¿u chÆ°a Ä‘á»§ mapping
    if len(brain_to_case) < len(brains):
        fallback_map = _fallback_map_brain_to_case(brains)
        for k, v in fallback_map.items():
            brain_to_case.setdefault(k, v)  # khÃ´ng ghi Ä‘Ã¨ meta

    df = attach_grade(df, brain_to_case, case_to_grade)

    # 4) Táº¡o nhÃ£n stratify tá»•ng há»£p
    strat_labels, bin_names = make_stratify_labels(df, min_per_stratum=MIN_PER_STRAT)
    df["strat_label"] = strat_labels

    ids = df["brain"].values
    strat = df["strat_label"].values

    # 5) Chia 70/15/15 (2 bÆ°á»›c)
    ids_train, ids_temp, strat_train, strat_temp = train_test_split(
        ids, strat,
        test_size=(1.0 - TRAIN_RATIO),
        random_state=SEED,
        stratify=strat
    )
    temp_val_ratio = VAL_RATIO / (VAL_RATIO + TEST_RATIO + 1e-12)
    ids_val, ids_test, _, _ = train_test_split(
        ids_temp, strat_temp,
        test_size=(1.0 - temp_val_ratio),
        random_state=SEED,
        stratify=strat_temp
    )

    # 6) GÃ¡n nhÃ£n split
    df["split"] = "none"
    df.loc[df["brain"].isin(ids_train), "split"] = "train"
    df.loc[df["brain"].isin(ids_val),   "split"] = "val"
    df.loc[df["brain"].isin(ids_test),  "split"] = "test"

    # 7) LÆ°u káº¿t quáº£
    df_sorted = df.sort_values(["split", "brain"]).reset_index(drop=True)

    out_dir.mkdir(parents=True, exist_ok=True)
    csv_path  = out_dir / "splits.csv"
    json_path = out_dir / "splits.json"
    txt_train = out_dir / "train.txt"
    txt_val   = out_dir / "val.txt"
    txt_test  = out_dir / "test.txt"

    df_sorted.to_csv(csv_path, index=False)

    payload = {
        "seed": SEED,
        "ratios": {"train": TRAIN_RATIO, "val": VAL_RATIO, "test": TEST_RATIO},
        "n_total": int(len(ids)),
        "n_train": int(len(ids_train)),
        "n_val": int(len(ids_val)),
        "n_test": int(len(ids_test)),
        "stratify_bins": sorted(df_sorted["strat_label"].unique().tolist()),
        "notes": "Stratify Æ°u tiÃªn: gradeÃ—hasETÃ—size_bin â†’ gradeÃ—hasET â†’ hasET â†’ all. size_bin báº±ng quantile trÃªn tumor_area_total.",
        "train": sorted(map(str, ids_train)),
        "val":   sorted(map(str, ids_val)),
        "test":  sorted(map(str, ids_test)),
    }
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)

    for path, id_list in ((txt_train, ids_train), (txt_val, ids_val), (txt_test, ids_test)):
        with open(path, "w", encoding="utf-8") as f:
            f.write("\n".join(sorted(map(str, id_list))) + "\n")

    # In tÃ³m táº¯t
    print("[OK] Saved splits to:")
    print(" -", csv_path)
    print(" -", json_path)
    print(" -", txt_train)
    print(" -", txt_val)
    print(" -", txt_test)
    print(f"[INFO] Summary: train={len(ids_train)} | val={len(ids_val)} | test={len(ids_test)} / total={len(ids)}")
    # PhÃ¢n bá»‘ grade giÃºp háº­u kiá»ƒm
    print(df_sorted.groupby(["split", "grade"]).size())


if __name__ == "__main__":
    main()
